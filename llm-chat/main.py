from tts import TextToSpeech
from llm import ChatModel
from stt import SpeechToText


# ä¸»åº”ç”¨é›†æˆ
import gradio as gr
from pydub import AudioSegment


def resample_pydub(input_path, output_path, target_sr=16000):
    """ä½¿ç”¨pydubè¿›è¡Œé‡é‡‡æ ·"""
    # åŠ è½½éŸ³é¢‘æ–‡ä»¶
    audio = AudioSegment.from_file(input_path)

    # è®¾ç½®å¸§ç‡ï¼ˆé‡‡æ ·ç‡ï¼‰å’Œå£°é“
    audio = audio.set_frame_rate(target_sr).set_channels(1)

    # å¯¼å‡ºä¸ºWAVæ–‡ä»¶
    audio.export(output_path, format="wav")

    return output_path


class VoiceChatSystem:
    def __init__(self):
        self.stt = SpeechToText()
        self.chat_model = ChatModel()
        self.tts = TextToSpeech()
        self.messages = [
            {
                "role": "system",
                "content": "ä½ æ˜¯ LLaMAï¼Œä½ éƒ½ç”¨ä¸­æ–‡å›ç­”æˆ‘",
            }
        ]
        self.chat_history = []

    def process_voice_input(self, audio_path):
        """å¤„ç†è¯­éŸ³è¾“å…¥çš„å…¨æµç¨‹"""
        try:
            # 1. è¯­éŸ³è½¬æ–‡æœ¬
            # è½¬ä¸€ä¸‹é‡‡æ ·ç‡
            audio_out = "tmp.wav"
            resample_pydub(audio_path, audio_out)

            user_text = self.stt.transcribe(audio_out)

            if not user_text:
                return "è¯†åˆ«å¤±è´¥ï¼Œè¯·é‡è¯•", None, self.chat_history

            # 2. ç”Ÿæˆå›å¤
            self.messages.append({"role": "user", "content": user_text})
            self.messages, bot_response = self.chat_model.generate_response(
                self.messages
            )
            
            self.chat_history.append((user_text, bot_response))

            clean_response = bot_response.replace("*", "")

            # 4. æ–‡æœ¬è½¬è¯­éŸ³
            audio_output_path = self.tts.synthesize(clean_response)

            return user_text, audio_output_path, self.chat_history

        except Exception as e:
            return f"å¤„ç†å‡ºé”™: {str(e)}", None, self.chat_history
    
    def process_text_input(self, user_text):
        """å¤„ç†è¯­éŸ³è¾“å…¥çš„å…¨æµç¨‹"""
        try:
            # 2. ç”Ÿæˆå›å¤
            self.messages.append({"role": "user", "content": user_text})
            self.messages, bot_response = self.chat_model.generate_response(
                self.messages
            )
            
            self.chat_history.append((user_text, bot_response))
            
            clean_response = bot_response.replace("*", "")

            # 4. æ–‡æœ¬è½¬è¯­éŸ³
            audio_output_path = self.tts.synthesize(clean_response)

            return user_text, audio_output_path, self.chat_history

        except Exception as e:
            return f"å¤„ç†å‡ºé”™: {str(e)}", None, self.chat_history


def create_gradio_interface():
    """åˆ›å»ºGradioç•Œé¢"""
    system = VoiceChatSystem()

    with gr.Blocks(title="è¯­éŸ³èŠå¤©ç³»ç»Ÿ", theme=gr.themes.Soft()) as demo:
        gr.Markdown("# ğŸ™ï¸ è¯­éŸ³èŠå¤©ç³»ç»Ÿ Demo")
        gr.Markdown("æ”¯æŒè¯­éŸ³å’Œæ–‡æœ¬è¾“å…¥ï¼Œä½¿ç”¨Whisper + llama + edge tts")

        with gr.Row():
            with gr.Column(scale=1):
                # è¯­éŸ³è¾“å…¥åŒºåŸŸ
                audio_input = gr.Audio(
                    sources=["microphone"], type="filepath", label="è¯­éŸ³è¾“å…¥"
                )
                audio_btn = gr.Button("å‘é€è¯­éŸ³", variant="primary")

                # æ–‡æœ¬è¾“å…¥åŒºåŸŸ
                text_input = gr.Textbox(
                    label="æ–‡æœ¬è¾“å…¥", placeholder="è¾“å…¥æ‚¨çš„é—®é¢˜...", lines=3
                )
                text_btn = gr.Button("å‘é€æ–‡æœ¬", variant="secondary")
                
                # æ¸…é™¤æŒ‰é’®
                clear_btn = gr.Button("æ¸…ç©ºå†å²", variant="stop")

            with gr.Column(scale=2):
                # æ˜¾ç¤ºè¯†åˆ«ç»“æœ
                recognition_text = gr.Textbox(label="è¯†åˆ«ç»“æœ", interactive=False)

                # éŸ³é¢‘è¾“å‡º
                audio_output = gr.Audio(label="è¯­éŸ³å›å¤", autoplay=True)

                # èŠå¤©å†å²
                chatbot = gr.Chatbot(label="å¯¹è¯å†å²", height=400)
                
                

        # äº‹ä»¶ç»‘å®š
        audio_btn.click(
            fn=system.process_voice_input,
            inputs=[audio_input],
            outputs=[recognition_text, audio_output, chatbot],
        )

        text_btn.click(
            fn=system.process_text_input,
            inputs=[text_input],
            outputs=[audio_output, audio_output, chatbot],
        )

        
        clear_btn.click(
            fn=lambda: ([], []),
            inputs=[],
            outputs=[chatbot, recognition_text]
        )

    return demo


if __name__ == "__main__":
    # å¯åŠ¨åº”ç”¨
    demo = create_gradio_interface()
    demo.launch()
